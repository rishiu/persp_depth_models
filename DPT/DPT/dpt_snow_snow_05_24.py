# -*- coding: utf-8 -*-
"""DPT_snow_snow_05_24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1APvcXwV9brmAJDadLZHm3k-6r5loySDo

# Note

LEARNING RATE
  set to what it is in the paper, but the paper doesn't say for fine-tuning
  no learning rate scheduler

OPTIMIZER
  The paper says they use Multi-Objective Optimization with Adam optimizer
  Not sure what multiple objectives are used 
  (possibly has something to do with dataset mixing, not in fine-tuning)
  Used Adam optimizer only

BATCH SIZE
  They used batch size 16
  We ran out of memory, so used batch size 8

SCALE AND SHIFT WITH INVERSION
  We changed one line of code
  We invert the image first, then do the calculated scale and shift
  This is because our lidar images have really small values (1e-7)
  So we cannot invert those to calculate pre-invert scale and shift

# Mount Drive
"""

# Commented out IPython magic to ensure Python compatibility.
# Mount the google drive
#from google.colab import drive
#drive.mount('/content/gdrive', force_remount=True)

# cd only once to the wanted dir at the beginning
# %cd '/content/gdrive/Shareddrives/SnowGeneration'

"""# Copy Data

"""

# Creates the directories needed to unzip dataset
#!mkdir /content/Dataset

# Unzips the training and validation dataset
# Change if you want to use a different Dataset

#!cp ./Data/dense_Depth_MonoDepth.zip /content/Dataset/ 
#!unzip -q /content/Dataset/dense_Depth_MonoDepth.zip -d /content/Dataset/
#!rm /content/Dataset/dense_Depth_MonoDepth.zip

"""# Install Package"""

#!pip install -r DPT/requirements.txt
#!pip install tensorboard
#!pip install tensorboardX
#!pip install tensorflow

"""# Library"""

# Commented out IPython magic to ensure Python compatibility.
"""Compute depth maps for images in the input folder.
"""
import sys
sys.path.append('/content/gdrive/Shareddrives/SnowGeneration/DPT')
import os
import cv2
import argparse
from PIL import Image, ImageChops, ImageOps, ImageEnhance
import random
from natsort import natsorted
from glob import glob
from pathlib import Path

#from util import io

from dpt.models import DPTDepthModel
from dpt.transforms import Resize, NormalizeImage, PrepareForNet

import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms.functional as TF
from torch.autograd import Variable
import functools
from torch.nn import init
import torchvision
from torchvision.transforms import Compose

from tqdm import tqdm
import numpy as np
from tensorboardX import SummaryWriter
# %load_ext tensorboard
# %matplotlib inline
import matplotlib.pyplot as plt

"""# Helper"""

# Plot image
def show_img(img, title=None, figsize=(15, 15)):
  #img = (img+1)/2
  plt.figure(figsize=figsize)
  plt.imshow(img)
  if title:
    plt.title(title)
  plt.show()

"""# Dataloader"""

# DataLoaders for Training and Validation set
class DPTData(Dataset):
  """
    The dataset class for weather net training and validation.

    Parameters:
        root_dir_list (list) -- list of dirs for the dataset.
        is_train (bool) -- True for training set.
  """
  def __init__(self, root_dir_list, is_train=True):
    super(DPTData, self).__init__()

    self.is_train = is_train
    self.img_paths = []
    self.depth_paths = []
    for root_dir in root_dir_list:
      self.img_paths += natsorted(glob(f"{root_dir}/imgs/*.jpg"))
      self.depth_paths += natsorted(glob(f"{root_dir}/depth/*.npy"))
       
    # number of images
    self.data_len = len(self.img_paths)
  
  def __len__(self):
    # return 16
    return self.data_len

  def get_scene_indices(self):
    return self.scene_indices
  
  def __getitem__(self, index):
    inp_path = self.img_paths[index]
    inp_img = Image.open(inp_path)
    filename = inp_path.split('/')[-1][:-4]

    depth_path = self.depth_paths[index]
    #depth_img = Image.open(depth_path)
    depth_img = np.load(depth_path)

    # To numpy
    inp_img = np.array(inp_img, dtype=np.float32)
    depth_img = np.array(depth_img, dtype=np.float32)

    if not np.isfinite(inp_img).all() or not np.isfinite(depth_img).all():
      print("Non finite!")

    #print(depth_img.shape)
    #print(inp_img.shape)

    inp_img *= 1/255.0
    #depth_img /= np.max(depth_img)
    # Crop Code
    h = inp_img.shape[0]
    w = inp_img.shape[1]
    # Crop out top 200
    #inp_img = inp_img[200:h, :, :]
    #lidar_img = lidar_img[200:h, :]
    # Resize to height 384
    inp_img = cv2.resize(inp_img, (384, 384), interpolation=cv2.INTER_NEAREST)
    #lidar_img = cv2.resize(lidar_img, (1058, 384), interpolation=cv2.INTER_NEAREST)
    # Random Crop for square
    cc_x = random.randint(0, 512-384)
    cc_y = random.randint(0, 512-384)
    #inp_img = inp_img[cc_y:cc_y+384, cc_x:cc_x+384,:]
    #depth_img = np.expand_dims(depth_img, axis=2)
    #depth_img = depth_img[cc_y:cc_y+384, cc_x:cc_x+384,:]

    inp_img = (inp_img - .5) / .5
    
    inp_img = torch.from_numpy(inp_img).permute((2,0,1))
    depth_img = torch.from_numpy(depth_img).permute((2,0,1))

    # Data augmentations: flip x, flip y, rotate by (90, 180, 270), combinations of flipping and rotating
    if self.is_train:
      aug = random.randint(0, 1)
    else:
      aug = 0
    
    if aug==1:
      inp_img = inp_img.flip(2)
      depth_img = depth_img.flip(2)

    # Dict for return
    # If using tanh as the last layer, the range should be [-1, 1]
    sample_dict = {
        'input_img': inp_img,
        'depth_img': depth_img,
        'file_name': filename
    }

    return sample_dict

# # Create the DataLoaders for training and validation
# train_dataset = DPTData(
#     root_dir_list=params['root_dir_list'],
#     is_train=True
# )

# train_loader = DataLoader(
#     dataset=train_dataset,
#     batch_size=1, 
# )

# for i in train_loader:
#   break

"""# Secheduler"""

"""
Linear warmup from: 
https://github.com/ildoonet/pytorch-gradual-warmup-lr/blob/master/warmup_scheduler/scheduler.py
"""

from torch.optim.lr_scheduler import _LRScheduler
from torch.optim.lr_scheduler import ReduceLROnPlateau

class GradualWarmupScheduler(_LRScheduler):
  """ Gradually warm-up(increasing) learning rate in optimizer.
  Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.
  Args:
      optimizer (Optimizer): Wrapped optimizer.
      multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.
      total_epoch: target learning rate is reached at total_epoch, gradually
      after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)
  """

  def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):
    self.multiplier = multiplier
    if self.multiplier < 1.:
      raise ValueError('multiplier should be greater thant or equal to 1.')
    self.total_epoch = total_epoch
    self.after_scheduler = after_scheduler
    self.finished = False
    super(GradualWarmupScheduler, self).__init__(optimizer)

  def get_lr(self):
    if self.last_epoch > self.total_epoch:
      if self.after_scheduler:
        if not self.finished:
          self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]
          self.finished = True
        return self.after_scheduler.get_last_lr()
      return [base_lr * self.multiplier for base_lr in self.base_lrs]

    if self.multiplier == 1.0:
      return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]
    else:
      return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]

  def step_ReduceLROnPlateau(self, metrics, epoch=None):
    if epoch is None:
      epoch = self.last_epoch + 1
    self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning
    if self.last_epoch <= self.total_epoch:
      warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]
      for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):
        param_group['lr'] = lr
    else:
      if epoch is None:
        self.after_scheduler.step(metrics, None)
      else:
        self.after_scheduler.step(metrics, epoch - self.total_epoch)

  def step(self, epoch=None, metrics=None):
    if type(self.after_scheduler) != ReduceLROnPlateau:
      if self.finished and self.after_scheduler:
        if epoch is None:
          self.after_scheduler.step(None)
        else:
          self.after_scheduler.step(epoch - self.total_epoch)
        self._last_lr = self.after_scheduler.get_last_lr()
      else:
        return super(GradualWarmupScheduler, self).step(epoch)
    else:
      self.step_ReduceLROnPlateau(metrics, epoch)

"""# Loss"""

"""
LOSS FUNCTIONS
"""
class ScaleInvariantLoss(nn.Module):
  #Scale Invariant Loss according to https://arxiv.org/pdf/1406.2283.pdf

  def __init__(self, eps=.5):
    super(ScaleInvariantLoss, self).__init__()
    self.eps = eps
  
  def forward(self, tar, est):
    diff = (torch.log(tar) - torch.log(est))
    l2 = torch.mean(torch.square(diff))
    scale_inv = torch.sum(diff)**2
    num_pixels = tar.size(dim=0)
    total = l2 - (self.eps/(num_pixels**2))*scale_inv
    return total

class SSITRIM(nn.Module):
  def __init__(self):
    super(SSITRIM, self).__init__()

  def forward(self, d, d_star):
    M = d.shape[2]*d.shape[3]
    M_80 = int(0.8 * M)
    d = d.flatten(start_dim=1)
    d_star = d_star.flatten(start_dim=1)
    t_d = torch.median(d, dim=1)[0]
    s_d = (torch.sum(torch.abs(d - t_d.unsqueeze(1))) + 1e-8) / M
    d = (d - t_d.unsqueeze(1)) / s_d
    t_dstar = torch.median(d_star, dim=1)[0]
    s_dstar = (torch.sum(torch.abs(d_star - t_dstar.unsqueeze(1))) + 1e-8) / M
    d_star = (d_star - t_dstar.unsqueeze(1)) / s_dstar
    diff = torch.abs(d - d_star)
    filter_diff = torch.topk(diff, k=M_80, dim=1, largest=False)[0]
    loss = torch.sum(filter_diff) / (2 * M)
    return loss

class ScaleInvariantGradientLoss(nn.Module):
  def __init__(self, scale):
    super(ScaleInvariantGradientLoss, self).__init__()
    self.scales = []
    for i in range(scale):
      self.scales.append(1 / (2**i))

  def interpolate(self, img, scale):
    return torch.nn.functional.interpolate(img, scale_factor=scale, mode="bilinear")

  def standardize(self, arr):
    M = arr.shape[2] * arr.shape[3]
    t = torch.median(arr.flatten(start_dim=1), dim=1)[0]
    t = t.reshape(-1,1,1,1)
    s = torch.sum(torch.abs(arr - t)) / M
    arr = (arr - t) / s
    return arr

  def forward(self, d, d_star):
    loss = torch.zeros(d.shape[0], device="cuda")
    d = self.standardize(d)
    d_star = self.standardize(d_star)

    for s in self.scales:
      d_resize = self.interpolate(d, s)
      d_star_resized = self.interpolate(d_star, s)

      R = d_resize - d_star_resized

      R_x = torch.mean(torch.abs(R[:,:,:,:-1] - R[:,:,:,1:]), axis=(1,2,3))
      R_y = torch.mean(torch.abs(R[:,:,:-1,:] - R[:,:,1:,:]), axis=(1,2,3))

      R_grad = R_x + R_y

      loss += R_grad
    mloss = torch.mean(loss)
    return mloss



def SmoothLoss(disp, img):
  """Computes the smoothness loss for a disparity image
  The color image is used for edge-aware smoothness
  """
  grad_disp_x = torch.abs(disp[:, :, :, :-1] - disp[:, :, :, 1:])
  grad_disp_y = torch.abs(disp[:, :, :-1, :] - disp[:, :, 1:, :])

  grad_img_x = torch.mean(torch.abs(img[:, :, :, :-1] - img[:, :, :, 1:]), 1, keepdim=True)
  grad_img_y = torch.mean(torch.abs(img[:, :, :-1, :] - img[:, :, 1:, :]), 1, keepdim=True)

  grad_disp_x *= torch.exp(-grad_img_x)
  grad_disp_y *= torch.exp(-grad_img_y)

  return grad_disp_x.mean() + grad_disp_y.mean()

"""# Training Parameters"""

# Training config parameters
# may want to move to a .yml file later, done like this for now for simplicity

# Parameters
params = {
  'batch_size': 8, # batch size
  'num_epochs': 100, # number of epochs to train
  'warmup_epochs': 4, # number of epochs for warmup
  'initial_lr': 1e-4, # initial learning rate used by scheduler
  'min_lr': 1e-6, # minimum learning rate used by scheduler
  'val_epoch': 1, # validation done every k epochs
  'save_every': 5, # save every k epoch
  'save_dir': './checkpoints/syn_data',
  'root_dir_list': [
      '/usr/project/depth_models/depth_data/ft/train/'
    ], # Dir for the training data
  'val_dir_list': [
      '/usr/project/depth_models/depth_data/ft/val/'
    ], # Dir for the validation data
  'scale':  9994.173746794286, # scale for Dense Dataset
  'trans' : 13.881029101274752, # translation for Dense Dataset
  'masked_ssi_loss_weight': False, # weight for masked l1 loss (only where lidar points are)
  'smooth_loss_weight': False, # weight for smooth loss
  'ssi_trim_loss_weight': 1.0,
  'scale_inv_grad_loss_weight': 0.5,
  'resume_train': False, # begin training using loaded checkpoint
  'model_path': None, # Dir to load model weights
  'tensorboard_log_step_train': 100, # Number of steps to log into tensorboard when training
  'tensorboard_log_step_val': 1, # This number will be updated automatically based after creating the dataloaders
}

torch.manual_seed(100)
np.random.seed(100)

# Create dir to save the weights
Path(params['save_dir']).mkdir(parents=True, exist_ok=True)

# Set up tensorboard SummaryWriter and directories
writer = SummaryWriter(os.path.join(params['save_dir'], 'tensorboard'))

"""# Training Loop"""

# Create the DataLoaders for training and validation
train_dataset = DPTData(
    root_dir_list=params['root_dir_list'],
    is_train=True
)

train_loader = DataLoader(
    dataset=train_dataset,
    batch_size=params['batch_size'], 
    num_workers=2,
    shuffle=True,
    drop_last=True,
    pin_memory=True
)

val_dataset = DPTData(
    root_dir_list=params['val_dir_list'],
    is_train=False,
    )

val_loader = DataLoader(
    dataset=val_dataset, 
    batch_size=params['batch_size'], 
    num_workers=2, 
    shuffle=True, 
    drop_last=True, 
    pin_memory=True)

print('Train set length:', len(train_dataset))
print('Val set lenth:', len(val_dataset))

# Adjust the log freq based on the number of training and val samples
params['tensorboard_log_step_val'] = int(params['tensorboard_log_step_train'] * len(val_dataset) / len(train_dataset))

model = DPTDepthModel(
            path=None,
            scale=1,
            shift=0,
            invert=True,
            backbone="vitb_rn50_384",
            non_negative=True,
            enable_attention_hooks=False,
        )
model.cuda()

key_name_list = ['blocks']
backbone_params = []
block_params = []
normal_params = []
for cur_name, parameters in model.named_parameters():
  if 'blocks' in cur_name and not 'backbone' in cur_name:
    block_params.append(parameters)
  elif 'backbone' in cur_name:
    backbone_params.append(parameters)
  else:
    normal_params.append(parameters)

optimizer = optim.Adam(
    [{"params": normal_params},
     {"params": backbone_params, "lr": 0.0},
     {"params": block_params, "lr": params["initial_lr"] / 10}], 
    lr=params['initial_lr'], 
    betas=(0.9, 0.999), 
    eps=1e-8
    )

scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(
  optimizer, 
  params['num_epochs'] - params['warmup_epochs'], 
  eta_min=params['min_lr'])

scheduler = GradualWarmupScheduler(
  optimizer, 
  multiplier=1.0, 
  total_epoch=params['warmup_epochs'], 
  after_scheduler=scheduler_cosine)

optimizer.zero_grad()
optimizer.step()
scheduler.step() # To start warmup

criterion_masked_ssi = ScaleInvariantLoss().cuda()
ssi_trim = SSITRIM().cuda()
scale_inv_grad_loss = ScaleInvariantGradientLoss(scale=4).cuda()
L1_loss = nn.L1Loss().cuda()

start_epoch = 0

print(torch.__version__)

if params['resume_train']:
  print(f"Loading checkpoint {params['model_path']}")
  checkpoint = torch.load(params['model_path'])

  # Load Model
  model.load_state_dict(checkpoint['state_dict'])
  start_epoch = checkpoint['epoch'] + 1
  print(f"Resuming epoch: {start_epoch}")

  for i in range(start_epoch):
    scheduler.step()

  # # Load the optimizer we were using for that run
  # optimizer_first.load_state_dict(checkpoint['optimizer_first'])
  # optimizer_second.load_state_dict(checkpoint['optimizer_second'])

  print(f"Resuming first lr: {optimizer.param_groups[0]['lr']}")
else:
  print(f"Initial first lr: {optimizer.param_groups[0]['lr']}")

def get_s_t(depth_pred, depth_gt):
  depth_pred  = depth_pred.detach().cpu().numpy()
  depth_gt  = depth_gt.detach().cpu().numpy()  
  flattened_pred = depth_pred.flatten()
  flattened_gt = depth_gt.flatten()
  pred_mat = np.vstack([flattened_pred, np.ones(len(flattened_pred))]).T
  s, t = np.linalg.lstsq(pred_mat, flattened_gt, rcond=None)[0]
  return s, t

def get_sum_loss(net_out, gt, criterion):
  if isinstance(net_out, list):
    loss = 0
    for net_out_i in net_out:
      loss += criterion(net_out_i, gt)
  else:
    loss = criterion(net_out, gt)
  return loss

# TRAINING AND VALIDATION
# scale_sum = 0
# trans_sum = 0
# params['num_epochs'] = 1
for epoch in range(start_epoch, params['num_epochs']):
  print(epoch)
  epoch_loss = 0

  # TRAINING
  model.train()
  #train_loop = tqdm(train_loader, leave=False, position=0)
  #train_loop.set_description(f"Epoch {epoch}/{params['num_epochs']}")
  for batch_idx, batch_data in enumerate(tqdm(train_loader)):
    
    # Load the data
    input_img = batch_data['input_img'].cuda()
    depth_img = batch_data['depth_img'].cuda()

    # Check the current step
    current_step = epoch * len(train_loader) + batch_idx

    #########
    # Train #
    #########

    # Zero the gradients
    optimizer.zero_grad()

    # Forward pass through the entire model (both parts)
    out = model(input_img)
    #out = mout / torch.max(mout)
    #out = out * params['scale'] + params['trans']
    #out[out>100] = 100
    out = torch.unsqueeze(out, 1)

    # out = out.detach().cpu().squeeze().numpy()
    # plt.figure()
    # plt.imshow(out, cmap='jet')
    # plt.colorbar()
    # plt.show()
#     out_masked = out[lidar_img > 0]
#     lidar_img_masked = lidar_img[lidar_img > 0]
#     s,t =get_s_t(out_masked,lidar_img_masked )
#     scale_sum+=s
#     trans_sum+=t
# final_scale =   scale_sum/len(train_dataset)
# final_trans =   trans_sum/len(train_dataset)
    # Calculate losses between gt and output
    loss = 0

    if params['masked_ssi_loss_weight']:
      out_masked = out[depth_img>0]
      depth_img_masked = depth_img[depth_img>0]
      loss_ssi_masked = get_sum_loss(out_masked, depth_img_masked, criterion_masked_ssi)
      loss += params['masked_ssi_loss_weight'] * loss_ssi_masked
      loss_ssi_masked_log = loss_ssi_masked.item()

    if params['smooth_loss_weight']:
      loss_smooth = SmoothLoss(out, input_img)
      loss += params['smooth_loss_weight'] * loss_smooth
      loss_smooth_log = loss_smooth.item()

    if params['ssi_trim_loss_weight']:
      loss_ssi_trim = get_sum_loss(out, depth_img, ssi_trim)
      loss += params['ssi_trim_loss_weight'] * loss_ssi_trim
      loss_ssi_trim_log = loss_ssi_trim.item()

    if params['scale_inv_grad_loss_weight']:
      loss_scale_inv_grad = get_sum_loss(out, depth_img, scale_inv_grad_loss)
      loss += params['scale_inv_grad_loss_weight'] * loss_scale_inv_grad
      loss_scale_inv_grad_log = loss_scale_inv_grad.item()

    # Backwards pass and step
    loss.backward()
    optimizer.step()

    # Log
    #out_masked = out[depth_img>0]
    #depth_img_masked = depth_img[depth_img>0]
    epoch_loss += loss#get_sum_loss(out_masked, depth_img_masked, L1_loss).item()
    loss_log = loss.item()

    # Tensorboard
    if (current_step % params['tensorboard_log_step_train']) == 0:
      
      # Log loss
      writer.add_scalar('loss/train', loss_log, current_step)

      if params['masked_ssi_loss_weight']:
        writer.add_scalar('masked_ssi_loss/train', loss_ssi_masked_log, current_step)
      if params['smooth_loss_weight']:
        writer.add_scalar('smooth_loss/train', loss_smooth_log, current_step)
      if params['ssi_trim_loss_weight']:
        writer.add_scalar('ssi_trim_loss/train', loss_ssi_trim, current_step)
      if params['scale_inv_grad_loss_weight']:
        writer.add_scalar('scale_inv_grad_loss/train', loss_ssi_trim, current_step)
  
  # Print info
  print(
  f"Epoch: {epoch}\n"
  f"Train Loss: {epoch_loss / len(train_loader):.4f}\n"
  f"Learning Rate First {optimizer.param_groups[0]['lr']:.8f}\t"
  )
  out_plot = out[0, 0, :, :].detach().cpu()
  depth_img_plot = depth_img[0, 0, :, :].cpu()
  plt.figure()
  plt.imshow(input_img[0, :, :, :].cpu().permute(1, 2, 0) * .5 + .5)
  plt.figure()
  plt.imshow(out_plot, cmap = 'jet')
  plt.colorbar()
  plt.figure()
  plt.imshow(depth_img_plot, cmap = 'jet')
  plt.colorbar()
  plt.savefig("epoch_"+str(epoch)+".jpg")
  plt.close()

  ##############
  # Validation #
  ##############

  if epoch %  params['val_epoch'] == 0:
    model.eval()
    epoch_loss = 0

    val_loop = tqdm(val_loader, leave=False, position=0)
    val_loop.set_description('Val Epoch')
    for batch_idx, batch_data in enumerate(val_loop):
      
      # Load data
      input_img = batch_data['input_img'].cuda()
      depth_img = batch_data['depth_img'].cuda()

      # Check the current step
      current_step = epoch * len(val_loader) + batch_idx

      # Forward pass of model
      with torch.no_grad():
        out = model(input_img)
        #out = mout / torch.max(mout)
        #out = out * params['scale'] + params['trans']
        #out[out>100] = 100
        out = torch.unsqueeze(out, 1)

        # Calculate losses between pseudo-gt and output
        loss = 0

        if params['masked_ssi_loss_weight']:
          out_masked = out[depth_img>0]
          depth_img_masked = depth_img[depth_img>0]
          loss_ssi_masked = get_sum_loss(out_masked, depth_img_masked, criterion_masked_ssi)
          loss += params['masked_ssi_loss_weight'] * loss_ssi_masked
          loss_ssi_masked_log = loss_ssi_masked.item()

        if params['smooth_loss_weight']:
          loss_smooth = SmoothLoss(out, input_img)
          loss += params['smooth_loss_weight'] * loss_smooth
          loss_smooth_log = loss_smooth.item()

        if params['ssi_trim_loss_weight']:
          loss_ssi_trim = get_sum_loss(out, depth_img, ssi_trim)
          loss += params['ssi_trim_loss_weight'] * loss_ssi_trim
          loss_ssi_trim_log = loss_ssi_trim.item()

        if params['scale_inv_grad_loss_weight']:
          loss_scale_inv_grad = get_sum_loss(out, depth_img, scale_inv_grad_loss)
          loss += params['scale_inv_grad_loss_weight'] * loss_scale_inv_grad
          loss_scale_inv_grad_log = loss_scale_inv_grad.item()


        # if params['ssim_loss_weight']:
        #   loss_ssim = get_sum_loss(second_stage_out, target_img, criterion_neg_ssim)
        #   loss += params['ssim_loss_weight'] * loss_ssim
        #   loss_ssim_second_log = loss_ssim.item()
        
        #out_masked = out[depth_img>0]
        #depth_img_masked = depth_img[depth_img>0]
        epoch_loss += loss#get_sum_loss(out_masked, depth_img_masked, L1_loss).item()
        loss_log = loss.item()
      
        # Tensorboard
        if (current_step % params['tensorboard_log_step_val']) == 0:
          
          # Log loss
          writer.add_scalar('loss_second/val', loss_log, current_step)

          # Seperate loss
          if params['masked_ssi_loss_weight']:
            writer.add_scalar('masked_ssi_loss/val', loss_ssi_masked_log, current_step)
          if params['smooth_loss_weight']:
            writer.add_scalar('smooth_loss/val', loss_smooth_log, current_step)
          if params['ssi_trim_loss_weight']:
            writer.add_scalar('ssi_trim_loss/train', loss_ssi_trim, current_step)
          if params['scale_inv_grad_loss_weight']:
            writer.add_scalar('scale_inv_grad_loss/train', loss_ssi_trim, current_step)
    # Print info
    avg_val_loss = epoch_loss / len(val_loader)
    print(
        f"Val Epoch\t"
        f"Val Loss: {avg_val_loss:.4f}"
        )
    
    # Log images 
    out_plot = out[0, 0, :, :].cpu()
    depth_img_plot = depth_img[0, 0, :, :].cpu()
    plt.figure()
    plt.imshow(input_img[0, :, :, :].cpu().permute(1, 2, 0) * .5 + .5)
    plt.figure()
    plt.imshow(out_plot, cmap = 'jet')
    plt.colorbar()
    plt.figure()
    plt.imshow(depth_img_plot, cmap = 'jet')
    plt.colorbar()
    plt.savefig("val_epoch_"+str(epoch)+".jpg")
    plt.close()
  
  # Move the scheduler forward
  scheduler.step()

  # Save every few epochs
  if epoch % params['save_every'] == 0:
    print('Saving...')
    torch.save({
        'epoch': epoch, 
        'state_dict': model.state_dict(),
        'optimizer' : optimizer.state_dict()}, 
        os.path.join(params['save_dir'], f'model_epoch_{epoch}.pth')
        )
  
  # Tensorboard
  writer.flush()
# Close tensorboard
writer.close()

